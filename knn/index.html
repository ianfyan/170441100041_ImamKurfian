



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Data Mining">
      
      
        <link rel="canonical" href="https://ianfyan.github.io/170441100041_ImamKurfian/knn/">
      
      
        <meta name="author" content="Imam Kurfian">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>KNN - Data Mining</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#konsep-k-nn-k-nearest-neighbor" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://ianfyan.github.io/170441100041_ImamKurfian/" title="Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Mining
            </span>
            <span class="md-header-nav__topic">
              KNN
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/ianfyan/170441100041_ImamKurfian" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    ianfyan/170441100041_ImamKurfian
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Kmeans" class="md-tabs__link md-tabs__link--active">
        Kmeans
      </a>
    
  </li>

      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://ianfyan.github.io/170441100041_ImamKurfian/" title="Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/ianfyan/170441100041_ImamKurfian" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    ianfyan/170441100041_ImamKurfian
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Kmeans" class="md-nav__link">
      Kmeans
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        KNN
      </label>
    
    <a href="./" title="KNN" class="md-nav__link md-nav__link--active">
      KNN
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-definisi-k-nearest-neighbors" title="1. Definisi K-Nearest Neighbors" class="md-nav__link">
    1. Definisi K-Nearest Neighbors
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-cara-kerja-algoritma-k-nearest-neighbors-knn" title="2. Cara Kerja Algoritma K-Nearest Neighbors (KNN)" class="md-nav__link">
    2. Cara Kerja Algoritma K-Nearest Neighbors (KNN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Klasifikasi Terdekat (Nearest Neighbor Classification)" class="md-nav__link">
    Klasifikasi Terdekat (Nearest Neighbor Classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#banyaknya-k-tetangga-terdekat" title="Banyaknya k Tetangga Terdekat" class="md-nav__link">
    Banyaknya k Tetangga Terdekat
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-tahapan-algoritma-perhitungan-k-nn" title="3. Tahapan Algoritma Perhitungan K-NN" class="md-nav__link">
    3. Tahapan Algoritma Perhitungan K-NN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="4. Kelebihan dan Kekurangan dari Algoritma K-NN" class="md-nav__link">
    4. Kelebihan dan Kekurangan dari Algoritma K-NN
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../decision_tree/" title="Decision Tree" class="md-nav__link">
      Decision Tree
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-definisi-k-nearest-neighbors" title="1. Definisi K-Nearest Neighbors" class="md-nav__link">
    1. Definisi K-Nearest Neighbors
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-cara-kerja-algoritma-k-nearest-neighbors-knn" title="2. Cara Kerja Algoritma K-Nearest Neighbors (KNN)" class="md-nav__link">
    2. Cara Kerja Algoritma K-Nearest Neighbors (KNN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Klasifikasi Terdekat (Nearest Neighbor Classification)" class="md-nav__link">
    Klasifikasi Terdekat (Nearest Neighbor Classification)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#banyaknya-k-tetangga-terdekat" title="Banyaknya k Tetangga Terdekat" class="md-nav__link">
    Banyaknya k Tetangga Terdekat
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-tahapan-algoritma-perhitungan-k-nn" title="3. Tahapan Algoritma Perhitungan K-NN" class="md-nav__link">
    3. Tahapan Algoritma Perhitungan K-NN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="4. Kelebihan dan Kekurangan dari Algoritma K-NN" class="md-nav__link">
    4. Kelebihan dan Kekurangan dari Algoritma K-NN
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="konsep-k-nn-k-nearest-neighbor">Konsep K-NN (K-Nearest Neighbor)<a class="headerlink" href="#konsep-k-nn-k-nearest-neighbor" title="Permanent link">&para;</a></h1>
<h2 id="1-definisi-k-nearest-neighbors">1. Definisi K-Nearest Neighbors<a class="headerlink" href="#1-definisi-k-nearest-neighbors" title="Permanent link">&para;</a></h2>
<p>K-nearest neighbor (k-NN atau KNN) adalah sebuah metode atau algoritme untuk melakukan klasifikasi  suatu data berdasarkan data pembelajaran (<em>train data sets</em>), yang diambil dari k tetangga terdekatnya (<em>nearest neighbors</em>). Dimana k merupakan banyaknya tetangga terdekat. Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan <em>Euclidean Distance</em>, atau dapat juga menggunakan rumus jarak yang lain.</p>
<p>Dalam mengklasifikasikan data baru, KNN ini perlu fakta/ data yang sudah ada yang digunakan sebagai data training sebagai acuan klasifikasi. KNN menjadi algoritma pembelajaran non-parametrik, maksudnya yaitu metode ini tidak menjadi sebuah asumsi tentang apa pun dengan data yang menjadi acuan klasifikasi. KNN menjadi sebuah fitur yang sangat berguna karena sebagian besar data dunia nyata tidak benar-benar mengikuti asumsi teoretis, misalnya: <em>linear-separability</em>, <em>uniform distribution</em>, dll.</p>
<p>Pembahasan pada halaman ini akan melihat bagaimana KNN dapat diimplementasikan dengan <em>library "Scikit-Learn Python"</em>. Namun, kita juga perlu tahu bagaimana teori dari metode KNN ini beserta kelebihan dan kekurangannya.</p>
<h2 id="2-cara-kerja-algoritma-k-nearest-neighbors-knn">2. Cara Kerja Algoritma K-Nearest Neighbors (KNN)<a class="headerlink" href="#2-cara-kerja-algoritma-k-nearest-neighbors-knn" title="Permanent link">&para;</a></h2>
<p>K-nearest neighbors melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik <strong>c</strong> pada ruang dimensi banyak.</p>
<h4 id="klasifikasi-terdekat-nearest-neighbor-classification">Klasifikasi Terdekat (Nearest Neighbor Classification)<a class="headerlink" href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Permanent link">&para;</a></h4>
<p>Data baru yang diklasifikasi selanjutnya diproyeksikan pada ruang dimensi banyak yang telah memuat titik-titik c data pembelajaran. Proses klasifikasi dilakukan dengan mencari titik <strong><em>c</em></strong> terdekat dari <strong><em>c-baru</em></strong> (<em>nearest neighbor</em>)<em>.</em> Teknik pencarian tetangga terdekat yang umum dilakukan dengan menggunakan formula jarak euclidean.</p>
<p>Teknik pencarian tetangga terdekat disesuaikan dengan dimensi data, proyeksi, dan kemudahan implementasi oleh pengguna.</p>
<h4 id="banyaknya-k-tetangga-terdekat">Banyaknya k Tetangga Terdekat<a class="headerlink" href="#banyaknya-k-tetangga-terdekat" title="Permanent link">&para;</a></h4>
<p>Untuk menggunakan algoritma k nearest neighbors, perlu ditentukan banyaknya k tetangga terdekat yang digunakan untuk melakukan klasifikasi data baru. Banyaknya k, sebaiknya merupakan angka ganjil, misalnya k = 1, 2, 3, dan seterusnya. Penentuan nilai k dipertimbangkan berdasarkan banyaknya data yang ada dan ukuran dimensi yang dibentuk oleh data. Semakin banyak data yang ada, angka k yang dipilih sebaiknya semakin rendah. Namun, semakin besar ukuran dimensi data, angka k yang dipilih sebaiknya semakin tinggi.</p>
<h2 id="3-tahapan-algoritma-perhitungan-k-nn">3. Tahapan Algoritma Perhitungan K-NN<a class="headerlink" href="#3-tahapan-algoritma-perhitungan-k-nn" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Bagi data menjadi data training dan data testing</p>
</li>
<li>
<p>Menentukan parameter K sebagai banyaknya jumlah tetangga terdekat dengan objek baru. Banyaknya k, sebaiknya merupakan angka ganjil, misalnya k = 1, 2, 3, dan seterusnya. </p>
</li>
<li>
<p>Menghitung jarak antar data baru terhadap semua data yang telah di training menggunakan jarak Euclidean. Rumus Euclidean Distance sebagai berikut :</p>
</li>
</ol>
<p><img alt="mkdocs for material" src="../assets/images/euclidean.png" /></p>
<ol>
<li>
<p>Urutkan hasil perhitungan tersebut  dengan data training secara <em>ascending</em> (berurutan dari nilai tinggi ke rendah) dan menentukan tetangga terdekat berdasarkan jarak minimum K</p>
</li>
<li>
<p>Mengumpulkan Klasifikasi nearest neighbor berdasarkan nilai k</p>
</li>
<li>
<p>Dengan menggunakan kategori nearest neighbor yang paling mayoritas atau frekuensi terbanyak maka dapat diprediksikan sebagai hasil klasifikasi data baru.</p>
</li>
</ol>
<h2 id="4-kelebihan-dan-kekurangan-dari-algoritma-k-nn">4. Kelebihan dan Kekurangan dari Algoritma K-NN<a class="headerlink" href="#4-kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="Permanent link">&para;</a></h2>
<p>​   <strong>Kelebihan</strong> :</p>
<ul>
<li>Mudah dipahami dan diimplementasikan</li>
</ul>
<p>Untuk mengklasifikasi instance x menggunakan kNN, kita cukup mendefinisikan fungsi untuk menghitung jarak antar-instance, menghitung jarak x dengan semua instance lainnya berdasarkan fungsi tersebut, dan menentukan kelas x sebagai kelas yang paling banyak muncul dalam k instance terdekat.</p>
<ul>
<li>
<p>Lebih efektif di data training yang besar</p>
</li>
<li>
<p>Dapat menghasilkan data yang lebih akurat</p>
</li>
</ul>
<p><strong>Kekurangan</strong> :</p>
<ul>
<li>
<p>Perlu ditentukan nilai k yang paling optimal yang menyatakan jumlah tetangga terdekat</p>
</li>
<li>
<p>Biaya komputasi cukup tinggi karena perhitungan jarak harus dilakukan pada setiap query instance bersama-sama dengan seluruh instan dari training sample</p>
</li>
</ul>
<h1 id="_1"><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<h1 id="langkah-perhitungan-k-nearest-neighbors-di-excell">Langkah Perhitungan  K-Nearest Neighbors Di Excell<a class="headerlink" href="#langkah-perhitungan-k-nearest-neighbors-di-excell" title="Permanent link">&para;</a></h1>
<p>Berikut adalah sebagian datanya :</p>
<p><img alt="" src="../assets/images/knn0.JPG" /></p>
<p><strong>[ LANGKAH 1 ]</strong></p>
<p>Dari data Iris ambilah data <strong>testing</strong>. Disini data testing diambil sebanyak 15 data, 5 dari <strong>class iris-setosa</strong>, 5 dari <strong>iris-versicolor</strong>, dan 5 dari data <strong>iris-virginica.</strong> Pisahkan  15 data <strong>testing</strong> dan data hasil pengurangan masing-masing 15 dan 135 data. Berikut adalah data <strong>testing</strong> yang diambil :</p>
<p><img alt="" src="../assets/images/knn1 - Copy.JPG" /></p>
<p>[ LANGKAH 2 ]**</p>
<p>Menghitung kuadrat jarak <strong>eucliden</strong> objek terhadap data <strong>training</strong> yang diberikan. Jarak dihitung dari 15 data <strong>testing</strong> terhadap 135 data dari hasil pengurangan, menggunakan rumus berikut :</p>
<p><img alt="" src="../assets/images/knn2.JPG" /></p>
<p>Dalam Microsoft Excel menggunakan rumus sebagai berikut :</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>=SQRT (POWER(x2 – x1)^2+(y2     – y1)^2+.......+(Zn – Zn))</td>
</tr>
</tbody>
</table>
<p>Penerapan di excel :</p>
<p><img alt="" src="../assets/images/knn3.JPG" /></p>
<p><img alt="" src="../assets/images/knn5.JPG" /></p>
<p><strong>[ LANGKAH 3 ]</strong></p>
<p>Mengurutkan data pada tahap 2 secara <strong><em>ascending</em></strong> :</p>
<p><img alt="" src="../assets/images/knn6.png" /></p>
<p><strong>[ LANGKAH 4]</strong></p>
<p>Klasifikasi <strong>nearest neighbor</strong> berdasarkan nilai k. Nilai k ditentukan sebanyak data sisa hasil pengurangan yakni 135 data.  Menggunakan kategori <strong>nearest neighbor</strong>, dengan melihat dari class yang paling mayoritas, maka dapat diprediksikan <strong>class</strong> pada objek tersebut. Misalnya, dengan menggunakan sampel data tersebut kita menentukan K=3 dari jarak 1 maka hasil <strong>cluster</strong> pada objek pengurutan adalah <strong>iris-setosa</strong> karena mayoritas class pada K=3 tersebut adalah <strong>iris-setosa</strong>.</p>
<p><img alt="" src="../assets/images/knn6.JPG" /></p>
<h1 id="implementasi-program">IMPLEMENTASI PROGRAM<a class="headerlink" href="#implementasi-program" title="Permanent link">&para;</a></h1>
<p>Pada bagian ini, membahas bagaimana implementasi algoritma k-nearest neighbors dengan Scikit-Learn Python. Kita akan menggunakan dataset iris yang terkenal untuk contoh KNN ini. Dataset terdiri dari empat atribut: sepal-width, sepal-length, petal-width dan petal-length. Ini adalah atribut dari jenis spesifik tanaman iris. Fungsinya adalah untuk memprediksi kelas tanaman ini. Ada tiga kelas dalam dataset: Iris-setosa, Iris-versicolor dan Iris-virginica. Rincian lebih lanjut dari dataset tersedia <a href="https://github.com/abdurrouf211214/download/blob/master/Iris_.csv">di sini</a>.</p>
<p>Berikut langkah-langkah implementasi KNN: </p>
<h4 id="mengimpor-library-python">Mengimpor <em>Library python</em><a class="headerlink" href="#mengimpor-library-python" title="Permanent link">&para;</a></h4>
<p>Hal pertama yang kita lakukan untuk membuat program prediksi menggunakan metode KNN di python. Terlebih dahulu kita harus import beberapa library yang nantinya diperlukan dalam program ini antara lain import pandas  dan sklearn. Library pandas akan kita gunakan untuk mengambil data Iris kita sedangkan sklearn sebagai library yang mempunyai fungsi Kneighbors yang kita butuhkan nantinya. Berikut kode programnya :</p>
<div class="codehilite"><pre><span></span>import pandas as pd 
from sklearn.neighbors import KNeighborsClassifier
from sklearn import model_selection
from sklearn.model_selection import train_test_split
</pre></div>

<h4 id="mengambil-dataset">Mengambil Dataset<a class="headerlink" href="#mengambil-dataset" title="Permanent link">&para;</a></h4>
<p>Selanjutnya kita akan mengambil dataset iris kita, caranya adalah dengan menggunakan library pandas yang telah kita import sebelumnya. Berikut kodenya :</p>
<div class="codehilite"><pre><span></span>df=pd.read_csv(&#39;Iris.csv&#39;)
</pre></div>

<p>Pada kode diatas tertulis <em>pd.read_csv</em> , bukan <em>pandas.read_csv</em>  karena sebelumnya kita mengimpor pandas sebagai <em>pd</em>  sehingga saat kita ingin menggunakan <em>pandas</em>  kita hanya perlu mengetik <em>pd</em> saja.</p>
<h4 id="inisiasi-kneighbors-classifier">Inisiasi Kneighbors Classifier<a class="headerlink" href="#inisiasi-kneighbors-classifier" title="Permanent link">&para;</a></h4>
<p>Setelah data sudah ada, kita harus menginisiasi fungsi dari Kneighbors sendiri. Disini kita akan memasukkan fungsi KNN kedalam variabel clf sehingga nantinya saat kita memerlukannya kita hanya perlu memanggil variabel <em>clf</em> saja. Adapun maksud dri <em>n_neighbors=3</em> dibawah adalah untuk mendefinisikan jumlah tetangga.</p>
<div class="codehilite"><pre><span></span>clf=KNeighborsClassifier(n_neighbors=3)
</pre></div>

<h4 id="split-dataset">Split Dataset<a class="headerlink" href="#split-dataset" title="Permanent link">&para;</a></h4>
<p>Perlu diketahui, saat kita menggunakan program prediksi dengan data training dan data testing yang sama, maka hasilnya tidak akan terlihat optimal. Oleh karena itu kita akan membagi dataset menjadi dua bagian, yaitu satu untuk data training dan satu untuk data testing. Untuk membagi dataset menjadi data training dan data testing dalam program, jalankan kode berikut:</p>
<div class="codehilite"><pre><span></span># Dataset validasi dataset
array = df.values
X = array[:,1:5]
Y = array[:,5]

# Sepertiga data sebagai bagian dari set tes
validation_size = 15

seed = 7
X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)

#Menyesuaikan set training
clf.fit(X_train, Y_train) 
</pre></div>

<h4 id="buat-file-prediksi">Buat File Prediksi<a class="headerlink" href="#buat-file-prediksi" title="Permanent link">&para;</a></h4>
<p>Setelah semua persiapan selesai, saatnya kita membuat prediksi menggunakan fungsi Kneighbors dalam python. Erikut syntax programnya :</p>
<div class="codehilite"><pre><span></span>#Predicting untuk Set Tes
pred_clf = clf.predict(X_validation

pred_clf_df = pd.DataFrame(pred_clf.reshape(15,1))

#Ganti nama kolom untuk menunjukkan prediksi
pred_clf_df.rename(columns={0:&#39;Prediction&#39;}, inplace=True)

#membentuk kembali dataset uji
X_validation_df = pd.DataFrame(X_validation.reshape(15 ,4))

#menggabungkan dua bingkai data panda di atas kolom untuk membuat dataset prediksi
pred_outcome = pd.concat([X_validation_df, pred_clf_df], axis=1, join_axes=[X_validation_df.index])

pred_outcome.rename(columns = {0:&#39;SepalLengthCm&#39;, 1:&#39;SepalWidthCm&#39;, 2:&#39;PetalLengthCm&#39;, 3:&#39;PetalWidthCm&#39;}, inplace=True)

del df[&#39;Id&#39;]

#menggabungkan prediksi dengan dataset asli
pred_comp = pd.merge(df,pred_outcome, on=[&#39;SepalLengthCm&#39;,&#39;SepalWidthCm&#39;,&#39;PetalLengthCm&#39;,&#39;PetalWidthCm&#39;])
</pre></div>

<p>pada syntax program diatas, kita menjalankan fungsi Kneighbors pada syntax <em>clf.predict.</em> dan kemudian membuat sebuah model dataframe dengan 15 baris dan 1 kolom. Dataframe ini akan digunakan untuk menyimpan data hasil prediksi agar bisa di cetak nantinya. Lalu setelah itu menggabungkannya dengan data asli agar bisa ditampilkan perbedaan antara data asli dengan hasil prediksi.</p>
<h4 id="menampilkan-data-hasil-prediksi">Menampilkan Data Hasil Prediksi<a class="headerlink" href="#menampilkan-data-hasil-prediksi" title="Permanent link">&para;</a></h4>
<p>Setelah dataframe selesai dibuat maka hal selanjutnya yang dilakukan adalah menampilkannya. Berikut syntaxnya :</p>
<div class="codehilite"><pre><span></span>print((pred_comp).head(15))
</pre></div>

<h4 id="membuat-prediksi-untuk-inputan-nilai-baru-diluar-dataset">Membuat Prediksi Untuk Inputan nilai baru diluar dataset<a class="headerlink" href="#membuat-prediksi-untuk-inputan-nilai-baru-diluar-dataset" title="Permanent link">&para;</a></h4>
<p>Sampai saat ini, prediksi yang dilakukan masih sebatas data yang ada pada dataset iris. Agar kita bisa menguji data lain selain yang ada pada data testing ketikkan kode berikut :</p>
<div class="codehilite"><pre><span></span>sl = input(&#39;Enter sepal length (cm): &#39;)
sw = input(&#39;Enter sepal width (cm): &#39;)
tl = input(&#39;Enter tepal length (cm): &#39;)
tw = input(&#39;Enter tepal width (cm): &#39;)
dataClass = clf.predict([[sl,sw,tl,tw]])
print (&quot;\n&quot;)
print(&#39;Prediction: &#39;), dataClass
</pre></div>

<p>hasil dari syntax program diatas adalah sebuah prediksi dari data yang diinputkan. Dengan ini program prdiksi menggunakan metode Kneighbors kita sudah selesai.</p>
<h2 id="_2"><a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<h2 id="referensi">Referensi<a class="headerlink" href="#referensi" title="Permanent link">&para;</a></h2>
<ul>
<li>Mayu Shinohara. 2017. Hyper Parameters Tuning of DTree,RF,SVM,kNN di <a href="https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn">https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn</a></li>
<li>informatika. 2017. Algoritma K-Nearest Neighbor (K-NN) di <a href="https://informatikalogi.com/algoritma-k-nn-k-nearest-neighbor/">https://informatikalogi.com/algoritma-k-nn-k-nearest-neighbor/</a></li>
<li>Asep Maulana Ismail. 2018. Cara Kerja Algoritma k-Nearest Neighbor (k-NN) di <a href="https://medium.com/bee-solution-partners/cara-kerja-algoritma-k-nearest-neighbor-k-nn-389297de543e">https://medium.com/bee-solution-partners/cara-kerja-algoritma-k-nearest-neighbor-k-nn-389297de543e</a></li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="Kmeans" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Kmeans
              </span>
            </div>
          </a>
        
        
          <a href="../decision_tree/" title="Decision Tree" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Decision Tree
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Imam Kurfian
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="http://struct.cc" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/squidfunk" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/squidfunk" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/squidfunk" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>